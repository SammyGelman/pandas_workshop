{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "220a8baa-9a79-4820-8acc-49b038d2e74f",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Welcome to our Jupyter Notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6c8d9eb-8e71-41e7-a201-008937fda9d5",
   "metadata": {},
   "source": [
    "# Jupyter Cells\n",
    "\n",
    "**Markdown** and **Code** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23b638b2-a2b8-4464-a952-8c80f76f0b30",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams['figure.figsize'] = [6, 4]\n",
    "\n",
    "from IPython.display import Image\n",
    "\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf3d240a-8a7e-4372-8ce4-81e2b77639e9",
   "metadata": {},
   "source": [
    "### Our Data\n",
    "Coutesry of **Kaggle**! \n",
    "\n",
    "    A machine learning and data science community. \n",
    "\n",
    "I hope you like movies."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef68748a-d029-4708-961e-8a28745632d2",
   "metadata": {},
   "source": [
    "### Loading in data\n",
    "\n",
    "Popular file type: comma-seperated value (**.csv**) files.\n",
    "\n",
    "Use the pandas read_csv function to load the .csv file as a dataframe.\n",
    "\n",
    "    df = pd.read_csv('foo.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef48c24f-b1d0-4d3f-8b02-0ebbd3a02c88",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the file \"imdb_movies.csv\" to a variable named df.\n",
    "\n",
    "df = pd.read_csv('imdb_movies.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e96e8ed-269d-4943-9ac8-84801d2f9ff9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Look at the top ten columns and see if how many of the movies you recognize.\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3070246f-2629-4f71-b860-bf851d901060",
   "metadata": {},
   "source": [
    "### Columns and Index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98da84da-c044-42f1-bb14-401ea65933b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print out the columns and index of the DataFrame below.\n",
    "print(\"Number of columns: \", len(df.columns))\n",
    "print(\"Number of rows: \", len(df.index))\n",
    "\n",
    "print(\"\\n\", df.columns, \"\\n\\n\")\n",
    "print(df.index,\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bc7a014-e5e0-4979-b27d-cf2cc44ba47c",
   "metadata": {},
   "source": [
    "#### Exploring Columns\n",
    "\n",
    "    df['column_name']\n",
    "\n",
    "or specific values in columns:\n",
    "\n",
    "    df.loc['index', 'column_name']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2111734-8236-4e9e-8205-fc125bb3ca63",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print out the name of the 30th entry of the df \n",
    "df.loc[30, 'names']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96f9a471-ec9f-4bf6-9326-b4d3d575e3f5",
   "metadata": {},
   "source": [
    "#### Slicing \n",
    "What if we want to inspect **multiple rows** or **multiple columns**?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4887d68-16eb-4899-b939-a59c9b0199c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print out the names first 10 and the last 10 rows\n",
    "\n",
    "print(df.loc[6:10, 'names'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89f85efe-3c32-4063-8a88-207e27d0e208",
   "metadata": {},
   "source": [
    "#### Adding Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c5652c2-9dbf-4643-a7fe-2f8474353e58",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create budget and revenue columns in units of a million dollars\n",
    "df[\"budget_m\"] = df[\"budget_x\"]/1000000\n",
    "df[\"revenue_m\"] = df[\"revenue\"]/1000000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0225f08-14d2-44eb-8ffc-e4d097e5a3b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"budget_m\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be6257a5-f8a2-426d-8148-fcf2ccf0d593",
   "metadata": {},
   "source": [
    "#### Mathematical Operations\n",
    "\n",
    "    sum(): Compute the sum of values.\n",
    "    mean(): Compute the mean of values.\n",
    "    median(): Compute the median of values.\n",
    "    std(): Compute the standard deviation.\n",
    "    var(): Compute the variance.\n",
    "    min(): Find the minimum value.\n",
    "    max(): Find the maximum value.\n",
    "    count(): Count the number of non-NA/null observations.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "715d8655-99aa-4c5a-8094-37324f48bc19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here\n",
    "total_budget = df[\"budget_m\"].sum()\n",
    "print(total_budget)\n",
    "\n",
    "total_rev = df[\"revenue_m\"].sum()\n",
    "print(total_rev)\n",
    "\n",
    "print(\"\\n\", \"Ratio of budget to revenue: \" ,total_rev/total_budget)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acf7d69a-882d-43f9-b603-1fc3438ad2db",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"revenue_m\"].min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09e295c6-302a-4465-b3e1-d0389dbf989f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"revenue_m\"].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7af2b2a-bdc1-4aad-987a-3f0612002877",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.nlargest(4, \"revenue_m\")[[\"names\", \"revenue_m\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "557d9fbc-c522-41f1-ab26-20fbfb0b09e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "Image(filename=\"assets/winner_400.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dc05869-98c7-4c65-b74e-6f3071acff62",
   "metadata": {},
   "outputs": [],
   "source": [
    "bins = plt.hist(df[\"budget_m\"], bins=100)\n",
    "plt.title(\"Historgram of Film Budgets\")\n",
    "plt.xlabel(\"Budget (million $)\")\n",
    "plt.ylabel(\"# of films\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e181afbe-b703-439f-8cc5-dcf6477726f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "bins = plt.hist(df[\"revenue_m\"], bins=100)\n",
    "plt.title(\"Historgram of Film Revenues\")\n",
    "plt.xlabel(\"Revenue (million $)\")\n",
    "plt.ylabel(\"# of films\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b08ec719-8f4e-49fe-bb1f-3bca2c74d865",
   "metadata": {},
   "source": [
    "#### Feature engineering\n",
    "\n",
    "    profit = revenue - budget\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac808bd3-e6cd-488a-a8c5-5779261c41e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a column called profit and add it to the DataFrame.\n",
    "\n",
    "df[\"profit_m\"] = df[\"revenue_m\"] - df[\"budget_m\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b9b5b21-732f-43dd-a113-8780e32199bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"profit_m\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03db822a-7172-45ff-9229-88ce067c82fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.nsmallest(4, \"profit_m\")[[\"names\", \"profit_m\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dafa310-08d0-4b7b-874e-b55341011f5c",
   "metadata": {},
   "source": [
    "#### Masking\n",
    "Creating masks is a convinient way to filter through data. \n",
    "\n",
    "By creating a condition and running over the data, we can create a mask of True/False statements.\n",
    "\n",
    "Operators in python are:\n",
    "\n",
    "    greater-than: >\n",
    "    less-than: <\n",
    "    equal: ==\n",
    "    not equal: !=\n",
    "    greater-than equal: >=\n",
    "    less-than equal: <=\n",
    "\n",
    "Lets see how they work in action!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e077ecb-e95e-4d19-b435-14b984158910",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Create an example array\n",
    "ex = np.array([0,1,2,3,4,5,6])\n",
    "print(\"This is the example array: \", ex)\n",
    "\n",
    "# Set a condition, greater-than or equal to three\n",
    "mask = ex >= 3\n",
    "print(\"This is the mask: \", mask)\n",
    "\n",
    "# use the mask to filter through the results\n",
    "print(\"These are the values in the array which pass the condition: \", ex[mask])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac79b545-7792-4b51-a4a2-9524953e43f2",
   "metadata": {},
   "source": [
    "Pandas is built to handle masks as well!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94d3ea12-a1c5-40e3-9045-1f3224fe8f75",
   "metadata": {},
   "outputs": [],
   "source": [
    "# search for films that profited over 250 million dollars\n",
    "\n",
    "# define the mask\n",
    "mask = df[\"profit_m\"] > 350\n",
    "\n",
    "# We can use the count method to see how many films managed to earn that much\n",
    "df.loc[mask,\"profit_m\"].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f295d7eb-282e-4b35-a5f1-9d6752ebcbb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Determine how many films netted a negative profit\n",
    "mask_neg_profit = df[\"profit_m\"] < 0\n",
    "df.loc[mask_neg_profit, \"profit_m\"].count()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5c19fb9-02cb-4d46-800a-42ab70849c68",
   "metadata": {},
   "source": [
    "### Avioding multiple masks: Query\n",
    "\n",
    "Built in method for handling multiple conditions\n",
    "\n",
    "    df.query()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e892f2d1-a694-4f16-87d3-b22f8489077b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The number of films at a loss cost under 2 million dollars to produce.\n",
    "\n",
    "df.query('budget_m > 100 and profit_m < 0')[\"profit_m\"].count()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "113036a7-09eb-4680-a1ee-986e90bc1c80",
   "metadata": {},
   "source": [
    "### Datetime\n",
    "Time is an important factor in determining trends.\n",
    "\n",
    "Pandas is ready for that!\n",
    "\n",
    "#### pd.to_datetime()\n",
    "\n",
    "The pd.to_datetime() function turns strings that meet a certain criteria into Timestamp objects. \n",
    "\n",
    "     pd.to_datetime(\"date_column\")\n",
    "\n",
    "This will output a series containing datetime objects."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d894f7ee-8ad6-4093-a5bf-f1a8aeb2d763",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"date_x\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adfd4334-a195-4373-a0d4-1e71af6d1656",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the pd.to_datetime function to define a new column in the DataFrame called \"date_time\" containing Timestamped objects\n",
    "\n",
    "df[\"date_time\"] = pd.to_datetime(df[\"date_x\"])\n",
    "type(df[\"date_time\"][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7eed4df-7191-425b-a260-52f2f0b5a4ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[0,\"date_time\"].month"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b227a54-3e5c-4e80-8560-1437d99c9754",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define lists to store values\n",
    "year = []\n",
    "month = []\n",
    "day = []\n",
    "\n",
    "# loop through Timestamp data\n",
    "for date in df[\"date_time\"]:\n",
    "    # Seperate year and month attributes and store appropriatly\n",
    "    year.append(date.year)\n",
    "    month.append(date.month)\n",
    "    day.append(date.day)\n",
    "\n",
    "# create new columns in df \n",
    "df[\"year\"] = year\n",
    "df[\"month\"] = month\n",
    "df[\"day\"] = day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bea42f0-a88b-4262-9ad6-dcc5ca7aaf87",
   "metadata": {},
   "outputs": [],
   "source": [
    "bins = plt.hist(df[\"day\"], bins=31)\n",
    "plt.title(\"Historgram of Film Revenues\")\n",
    "plt.xlabel(\"Day of the month\")\n",
    "plt.ylabel(\"# of films\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25e2a6bd-a52d-49eb-8916-fe59b6b8b3b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mean budget for 2022 and 2023\n",
    "\n",
    "mask = df[\"year\"] == 2022 \n",
    "print(\"mean budget 2022: \", df.loc[mask, \"budget_m\"].mean())\n",
    "\n",
    "mask = df[\"year\"] == 2023\n",
    "print(\"mean budget 2023\", df.loc[mask, \"budget_m\"].mean())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a06d4312-7f7b-4594-8a1c-d6779a1db6a8",
   "metadata": {},
   "source": [
    "### Mean budgets for every year?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90e1d1df-5ddc-47dc-9f1e-df579716610a",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df[\"year\"].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "718b13f4-f2e5-4e3c-813a-30fa459c8fc8",
   "metadata": {},
   "source": [
    "### To many masks\n",
    "\n",
    "There must be a better way to run these queries and calculations. \n",
    "\n",
    "#### Groupby\n",
    "\n",
    "        df.groupby(\"year\")\n",
    "\n",
    "The **unique values** of the column are the new index.\n",
    "\n",
    "For categorical data.\n",
    "\n",
    "\n",
    "        df.groupby(\"year\").agg('mean')\n",
    "\n",
    "        df.groupby(\"year\")[\"budget_m\"].agg('mean')\n",
    "\n",
    "        df.groupby(\"year\")[\"budget_m\"].agg(['sum','count','mean'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bab8341-c284-411c-9c00-bb1353a3f18f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the command listed above where we group the data by the year of their release date\n",
    "\n",
    "by_year = df.groupby(\"year\")\n",
    "budget_by_year = by_year[\"budget_m\"].agg('mean')\n",
    "budget_by_year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9473d079-b41e-42ec-a4c4-3b890d1a289a",
   "metadata": {},
   "outputs": [],
   "source": [
    "by_year = df.groupby(\"year\")\n",
    "budget_by_year = by_year[\"budget_m\"].agg(['std','mean','count','sum'])\n",
    "budget_by_year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8fb3c9b-c6e7-4a14-9a37-a4da751d658a",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(budget_by_year[\"mean\"])\n",
    "plt.title(\"Film Industry Budgets by Year\")\n",
    "plt.xlabel(\"Year\")\n",
    "plt.ylabel(\"Budget (million $)\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e23d9db-bd5c-43e4-8176-211e2affd6a7",
   "metadata": {},
   "source": [
    "## Additional Feature Engineering: \n",
    "\n",
    "### apply\n",
    "    \n",
    "    df.[column_name].apply(function_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59350432-2f81-4e37-97cb-35381f672e03",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to assign grades based on score\n",
    "def assign_grade(score):\n",
    "    thresh = [97, 93, 90, 87, 83, 80, 77, 73, 70, 67, 63, 60, 0]\n",
    "    grades = ['+A','A','-A','+B','B','-B','+C','C','-C','+D', 'D', '-D', 'F']\n",
    "    \n",
    "    i=0\n",
    "    \n",
    "    while True:\n",
    "        if score >= thresh[i]:\n",
    "            return grades[i]\n",
    "        i+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "502f538e-0727-43c4-bbec-70f6e02da505",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the apply function on the score column to create a new grade column\n",
    "df[\"grades\"] = df[\"score\"].apply(assign_grade)\n",
    "df[\"grades\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67c1cd02-2632-4bcb-932c-c2e56f739ee6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to assign grades based on score\n",
    "def assign_grade_code(score):\n",
    "    thresh = [97, 93, 90, 87, 83, 80, 77, 73, 70, 67, 63, 60, 0]\n",
    "    grades = range(1,14)\n",
    "    i=0\n",
    "    \n",
    "    while True:\n",
    "        if score >= thresh[i]:\n",
    "            return grades[i]\n",
    "        i+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28bd99c5-6bc4-4689-8670-07025d2d9272",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"grade_code\"] = df[\"score\"].apply(assign_grade_code)\n",
    "df[\"grade_code\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91092988-8203-48fd-a2c8-956641896e08",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make you're own groupby object - and sorry that the genre column is difficult to work with\n",
    "grades = ['+A','A','-A','+B','B','-B','+C','C','-C','+D', 'D', '-D', 'F']\n",
    "by_grade = df.groupby(\"grades\")\n",
    "rev_by_grade = by_grade[\"revenue_m\"].agg(\"mean\")\n",
    "organized_data = []\n",
    "\n",
    "for grade in grades:\n",
    "    organized_data.append(rev_by_grade.loc[grade])\n",
    "\n",
    "plt.plot(grades, organized_data)\n",
    "plt.title(\"Mean Revenue\")\n",
    "plt.xlabel(\"Grade\")\n",
    "plt.ylabel(\"Revenue (million $)\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "517ea46b-8ea6-4aa1-8079-07c1d93d7bdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# You can use lambda function within apply - lets use that to show a more elegant method to replace that nasty for-loop we used on the dates\n",
    "\n",
    "# Lambda are small annonymous functions. They work as: lambda input : output. Apply will funnel in all of the dates as input.\n",
    "df[\"year\"] = df[\"date_time\"].apply(lambda x : x.year)\n",
    "df[\"month\"] = df[\"date_time\"].apply(lambda x : x.month)\n",
    "\n",
    "# This was rushed so don't worry if you want to leave it for now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc7683b8-9879-4c7f-a0ec-19e4d52f8ba0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"genre\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c86d5fe-9eea-48d4-8d8f-ba5cbb6a76ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here is some code to make a new genre column which is a bit easier to work with\n",
    "def genre_to_list(genre):\n",
    "    if type(genre) != str:\n",
    "        return \"-\"\n",
    "    return genre.replace(',\\xa0' , ' ').split()\n",
    "\n",
    "df[\"genre_list\"] = df[\"genre\"].apply(genre_to_list)\n",
    "df[\"genre_list\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e0c13a1-06cf-4f34-8e8e-b2730159dfc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting script for line plot\n",
    "\n",
    "def plot_y_by_x(x, y, std=None, x_label=\"Year\", y_label=\"Mean Budget\", unit='(million $)'):\n",
    "    # Set the style of the plot\n",
    "    sns.set(style=\"whitegrid\")\n",
    "\n",
    "    # Create the plot\n",
    "    plt.figure(figsize=(8, 5))\n",
    "\n",
    "    # Plot mean budget\n",
    "    sns.lineplot(x=x, y=y, marker='o', label=y_label, color='b')\n",
    "\n",
    "    # Fill the area between mean_budget Â± std_budget\n",
    "    if std is not None:\n",
    "        plt.fill_between(x,\n",
    "                 y - std,\n",
    "                 y + std,\n",
    "                 color='b', alpha=0.2, label='Std Dev')\n",
    "\n",
    "    # Customize the plot\n",
    "    plt.title(f'{y_label} by {x_label}')\n",
    "    plt.xlabel(x_label)\n",
    "    plt.ylabel(f\"{y_label} {unit}\")\n",
    "    plt.legend()\n",
    "\n",
    "    # Display the plot\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "893d6eb6-50ae-4d38-a4dc-bce5a683e550",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lets first plot the average price of a movie by year. We can also include the standard deviarion \n",
    "y = budget_by_year[\"mean\"]\n",
    "std = budget_by_year[\"std\"]\n",
    "x = budget_by_year.index\n",
    "plot_y_by_x(x, y, std=std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e39d2f82-fb88-4448-8a9e-7a8b51ba341d",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = budget_by_year[\"sum\"]\n",
    "plot_y_by_x(x, y, y_label=\"Sum Budget\", unit=\"(million $)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7775099b-8f9b-4af2-b8af-55e931089c77",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Can you use the plotting script to plot the number of films released per year\n",
    "y = budget_by_year[\"count\"]\n",
    "# your code here\n",
    "plot_y_by_x(x, y, std=None, x_label=\"year\", y_label=\"Films Released\", unit = \" \")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3870532f-18a3-4d78-9349-323625bcecbc",
   "metadata": {},
   "source": [
    "### ML packages\n",
    "\n",
    "Scikit-learn has some great ML algorithms premade!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cce2cc9d-896b-43a6-ad2e-071301171bf8",
   "metadata": {},
   "source": [
    "#### One hot encoding\n",
    "The genre category seems like such a fun feature to inspect.  \n",
    "\n",
    "Many algorithms require a preprocessing step to encode categorical data to a algorithmically readable format. \n",
    "\n",
    "A popular method to doing this is one-hot encoding.\n",
    "\n",
    "    convert categorical data into an binary array where indecies in the array corresponds to thWee unique values of the feature in question. \n",
    "\n",
    "    colors = [\n",
    "            'blue',\n",
    "            'red',\n",
    "            'yellow',\n",
    "            'yellow',\n",
    "            'red'\n",
    "            ]\n",
    "            \n",
    "    colors_one_hot = [\n",
    "            [1,0,0],\n",
    "            [0,1,0]\n",
    "            [0,0,1]\n",
    "            [0,0,1]\n",
    "            [0,1,0]\n",
    "            ]\n",
    "\n",
    "In our case, where we have multiple genres for a single movie, we can add their one-hot vectors together to tell the model to consider attributes from both. \n",
    "\n",
    "This method is in imperfect because it does not factor in the potential coupling terms which likely emerge when combining genres together. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bc140e5-2299-42b3-b6a7-911bd2eca7ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "month_one_hot = (pd.get_dummies(df['month'].apply(pd.Series).stack()) + 0).reset_index(drop=True)\n",
    "month_one_hot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d342d87f-338c-4341-83a7-8b95f7688c4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "year_one_hot = (pd.get_dummies(df['year'].apply(pd.Series).stack()) + 0).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "169ea60c-9e48-41a7-83bc-62ddd83e627d",
   "metadata": {},
   "outputs": [],
   "source": [
    "country_one_hot = (pd.get_dummies(df['country'].apply(pd.Series).stack()) + 0).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddce0837-784a-4316-88d0-c739ed06cd26",
   "metadata": {},
   "outputs": [],
   "source": [
    "grades_one_hot = (pd.get_dummies(df['grades'].apply(pd.Series).stack()) + 0).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb0aa4f5-46a1-42eb-8cf0-b2ce0a47195e",
   "metadata": {},
   "outputs": [],
   "source": [
    "genre_one_hot = pd.get_dummies(df['genre_list'].apply(pd.Series).stack()).groupby(level=0).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd63df59-8745-4172-af3f-5dfdfa06cb2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lang_to_list(lang):\n",
    "    if type(lang) != str:\n",
    "        return \"-\"\n",
    "    return lang.replace(',\\xa0' , ' ').split()\n",
    "\n",
    "df[\"lang_list\"] = df[\"orig_lang\"].apply(lang_to_list).apply(lambda x : x[0])\n",
    "\n",
    "lang_one_hot = (pd.get_dummies(df['lang_list'].apply(pd.Series).stack()) + 0).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bd7adf1-edae-49f6-a79c-1e8181b3d24a",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_standard = StandardScaler().fit_transform(df[['revenue_m','budget_m','profit_m','score']])\n",
    "\n",
    "df_analysis = pd.concat([\n",
    "                        pd.DataFrame(X_standard),\n",
    "                        month_one_hot, \n",
    "                        year_one_hot,\n",
    "                        genre_one_hot,\n",
    "                        grades_one_hot,\n",
    "                        lang_one_hot,\n",
    "                        country_one_hot], \n",
    "                        \n",
    "                        axis=1,\n",
    "                        ignore_index=True\n",
    "                       )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "899de9d8-125e-4cdc-b8ce-8ec9a574a3fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dd99ee8-5ea7-461e-be96-1c4ed0c64afd",
   "metadata": {},
   "source": [
    "### Outliers\n",
    "\n",
    "Outliers can sometimes distrupt a models ability to pick up on trends"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45af0502-7b8b-48d3-adce-0e117289db63",
   "metadata": {},
   "outputs": [],
   "source": [
    "continuous_features = df.select_dtypes(include=[np.number]).columns.tolist()\n",
    "\n",
    "continuous_features.remove('year')\n",
    "continuous_features.remove('month')\n",
    "continuous_features.remove('budget_x')\n",
    "continuous_features.remove('score')\n",
    "\n",
    "X_scaled = StandardScaler().fit_transform(df[continuous_features])\n",
    "\n",
    "# Calculate Z-scores for the relevant columns\n",
    "z_scores = np.abs(X_scaled)\n",
    "\n",
    "# Define a threshold for outliers\n",
    "threshold = 3\n",
    "\n",
    "# Create a mask to identify non-outliers\n",
    "outlier_mask = (z_scores < threshold).all(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "233bcaf5-aece-47ae-807f-007845d5d878",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_cleaned = np.array(df_analysis)[outlier_mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b4cadb3-d417-455d-83d6-b542d7545e8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "perp = 50\n",
    "\n",
    "# t-SNE\n",
    "tsne = TSNE(n_components=2, perplexity=perp, random_state=42)\n",
    "tsne_results = tsne.fit_transform(X_cleaned)\n",
    "\n",
    "# Visualization\n",
    "plt.figure(figsize=(10, 6))\n",
    "scatter = plt.scatter(tsne_results[:, 0], tsne_results[:, 1], alpha=0.7, s=4)\n",
    "plt.title(f\"t-SNE Visualization, Perplexity: {perp}\")\n",
    "plt.xlabel(\"t-SNE Component 1\")\n",
    "plt.ylabel(\"t-SNE Component 2\")\n",
    "#plt.colorbar(scatter, label='Target Labels') \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "725912f8-6536-4132-a28b-199280218f31",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert text categories to numeric labels\n",
    "label_encoder = LabelEncoder()\n",
    "label = label_encoder.fit_transform(df[outlier_mask]['country'])\n",
    "\n",
    "# Visualization\n",
    "plt.figure(figsize=(10, 6))\n",
    "scatter = plt.scatter(tsne_results[:, 0], tsne_results[:, 1], c=label, alpha=0.7, s=4)\n",
    "plt.title(f\"t-SNE Visualization, Country\")\n",
    "plt.xlabel(\"t-SNE Component 1\")\n",
    "plt.ylabel(\"t-SNE Component 2\")\n",
    "\n",
    "\n",
    "# Create colorbar\n",
    "cbar = plt.colorbar(scatter)\n",
    "cbar.set_ticks(range(len(label_encoder.classes_)))  # Set the ticks to the number of classes\n",
    "cbar.set_ticklabels(label_encoder.classes_, size=6)  # Set the labels to the original category names\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "021821ca-ba78-4442-8f50-0b7e277fbb60",
   "metadata": {},
   "outputs": [],
   "source": [
    "label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "358319f2-f40d-4a35-a3da-16371a471e6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Convert text categories to numeric labels\n",
    "label_encoder = LabelEncoder()\n",
    "label = label_encoder.fit_transform(df[outlier_mask]['grade_code'])\n",
    "\n",
    "# Visualization\n",
    "plt.figure(figsize=(10, 6))\n",
    "scatter = plt.scatter(tsne_results[:, 0], tsne_results[:, 1], c=label, alpha=0.7, s=4)\n",
    "plt.title(f\"t-SNE Visualization, Grades\")\n",
    "plt.xlabel(\"t-SNE Component 1\")\n",
    "plt.ylabel(\"t-SNE Component 2\")\n",
    "\n",
    "\n",
    "# Create colorbar\n",
    "cbar = plt.colorbar(scatter)\n",
    "cbar.set_ticks(range(len(grades)))  # Set the ticks to the number of classes\n",
    "cbar.set_ticklabels(grades, size=7)  # Set the labels to the original category names\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3740aa0a-9688-42ed-b579-1692dac41528",
   "metadata": {},
   "source": [
    "### SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e334ad9-4eaf-4024-82bf-71e901ee6a6e",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "#X = df[['budget_m','score']]\n",
    "X = df[['budget_m']]\n",
    "y = df['revenue_m']\n",
    "\n",
    "X = pd.concat([X, \n",
    "               month_one_hot, \n",
    "                year_one_hot,\n",
    "                genre_one_hot,\n",
    "                lang_one_hot,\n",
    "                country_one_hot], \n",
    "                \n",
    "                axis=1,\n",
    "                ignore_index=True\n",
    "                       )\n",
    "\n",
    "# First, split into training+validation and test\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.2,\n",
    "                                                    shuffle=True)\n",
    "\n",
    "# Then, split the training+validation into training and validation\n",
    "X_test, X_val, y_test, y_val = train_test_split(X_temp, y_temp, test_size=0.5, \n",
    "                                                shuffle=True)\n",
    "\n",
    "scaler_x = MinMaxScaler()\n",
    "X_train = scaler_x.fit_transform(X_train)\n",
    "X_test = scaler_x.transform(X_test)\n",
    "X_val = scaler_x.transform(X_val)\n",
    "\n",
    "y_train_lower, y_train_upper = np.quantile(y_train, [0.1, 0.9])\n",
    "mask_train = (y_train > y_train_lower) & (y_train < y_train_upper)\n",
    "X_train = X_train[mask_train, :]\n",
    "y_train = y_train[mask_train]\n",
    "\n",
    "mask_test = (y_test > y_train_lower) & (y_test < y_train_upper)\n",
    "X_test = X_test[mask_test, :]\n",
    "y_test = y_test[mask_test]\n",
    "\n",
    "mask_val = (y_val > y_train_lower) & (y_val < y_train_upper)\n",
    "X_val = X_val[mask_val, :]\n",
    "y_val = y_val[mask_val]\n",
    "\n",
    "scaler_y = MinMaxScaler()\n",
    "y_train = scaler_y.fit_transform(np.expand_dims(y_train, axis=1))\n",
    "y_train = np.squeeze(y_train)\n",
    "\n",
    "y_test = scaler_y.transform(np.expand_dims(y_test, axis=1))\n",
    "y_test = np.squeeze(y_test)\n",
    "\n",
    "y_val = scaler_y.transform(np.expand_dims(y_val, axis=1))\n",
    "y_val = np.squeeze(y_val)\n",
    "\n",
    "model = SVR(kernel='rbf')\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "y_val_pred = model.predict(X_val)\n",
    "val_mse = mean_squared_error(y_val, y_val_pred)\n",
    "val_r2 = r2_score(y_val, y_val_pred)\n",
    "\n",
    "print(f'Validation Mean Squared Error: {val_mse:.4f}')\n",
    "print(f'Validation R^2 Score: {val_r2:.4f}')\n",
    "\n",
    "# Evaluate on the test set\n",
    "y_test_pred = model.predict(X_test)\n",
    "\n",
    "test_mse = mean_squared_error(y_test, y_test_pred)\n",
    "test_r2 = r2_score(y_test, y_test_pred)\n",
    "\n",
    "print(f'Test Mean Squared Error: {test_mse:.4f}')\n",
    "print(f'Test R^2 Score: {test_r2:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed7ac500-661c-46ed-bd1d-8f6c7d074eb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "budget = df[['budget_m']]\n",
    "y = df['revenue_m']\n",
    "\n",
    "X = pd.concat([\n",
    "                budget, \n",
    "                month_one_hot, \n",
    "                year_one_hot,\n",
    "                genre_one_hot,\n",
    "                lang_one_hot,\n",
    "                country_one_hot], \n",
    "                \n",
    "                axis=1,\n",
    "                ignore_index=True\n",
    "                       )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cbd591a-c437-4acb-b876-694c6dd37a69",
   "metadata": {},
   "outputs": [],
   "source": [
    "# First, split into training+validation and test\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.2,\n",
    "                                                    shuffle=True)\n",
    "\n",
    "# Then, split the training+validation into training and validation\n",
    "X_test, X_val, y_test, y_val = train_test_split(X_temp, y_temp, test_size=0.5, \n",
    "                                                shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7db602b4-0075-4a13-89af-e8227d0259b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler_x = MinMaxScaler()\n",
    "X_train = scaler_x.fit_transform(X_train)\n",
    "X_test = scaler_x.transform(X_test)\n",
    "X_val = scaler_x.transform(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccb7b5a5-b460-4165-9bea-bb65f3afc9aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_lower, y_train_upper = np.quantile(y_train, [0.0, 1.0])\n",
    "mask_train = (y_train > y_train_lower) & (y_train < y_train_upper)\n",
    "X_train = X_train[mask_train, :]\n",
    "y_train = y_train[mask_train]\n",
    "\n",
    "mask_test = (y_test > y_train_lower) & (y_test < y_train_upper)\n",
    "X_test = X_test[mask_test, :]\n",
    "y_test = y_test[mask_test]\n",
    "\n",
    "mask_val = (y_val > y_train_lower) & (y_val < y_train_upper)\n",
    "X_val = X_val[mask_val, :]\n",
    "y_val = y_val[mask_val]\n",
    "\n",
    "scaler_y = MinMaxScaler()\n",
    "y_train = scaler_y.fit_transform(np.expand_dims(y_train, axis=1))\n",
    "y_train = np.squeeze(y_train)\n",
    "\n",
    "y_test = scaler_y.transform(np.expand_dims(y_test, axis=1))\n",
    "y_test = np.squeeze(y_test)\n",
    "\n",
    "y_val = scaler_y.transform(np.expand_dims(y_val, axis=1))\n",
    "y_val = np.squeeze(y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f4ff4b2-b356-4e33-9b86-aa9dbdbdc3ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SVR(kernel='rbf')\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdca6690-ba32-4e33-8b54-f8e39a56264c",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_val_pred = model.predict(X_val)\n",
    "val_mse = mean_squared_error(y_val, y_val_pred)\n",
    "val_r2 = r2_score(y_val, y_val_pred)\n",
    "\n",
    "print(f'Validation Mean Squared Error: {val_mse:.4f}')\n",
    "print(f'Validation R^2 Score: {val_r2:.4f}')\n",
    "\n",
    "# Evaluate on the test set\n",
    "y_test_pred = model.predict(X_test)\n",
    "\n",
    "test_mse = mean_squared_error(y_test, y_test_pred)\n",
    "test_r2 = r2_score(y_test, y_test_pred)\n",
    "\n",
    "print(f'Test Mean Squared Error: {test_mse:.4f}')\n",
    "print(f'Test R^2 Score: {test_r2:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "714fb192-67bf-4be4-bd39-c7205d82e6c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Pearson Correlation Coefficient, Validation: \", np.corrcoef(y_val, y_val_pred)[0,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a43816b3-d7e4-449c-9e78-34cce062e189",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming you have your predictions in `y_pred` and actual values in `y_true`\n",
    "m, b = np.polyfit(y_test, y_test_pred, 1)\n",
    "x = np.linspace(min(y_test), max(y_test), 30)\n",
    "\n",
    "plt.scatter(y_test, y_test_pred, s=6)\n",
    "plt.xlabel('True Values')\n",
    "plt.ylabel('Predictions')\n",
    "plt.title('True Values vs Predictions')\n",
    "plt.plot(x, m*x+b, color='red')  # Identity line\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac632e18-f345-4b00-b63d-ed5b7c532b8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_val_inv = scaler_y.inverse_transform(np.expand_dims(y_val, axis=1))\n",
    "y_val_inv_pred = scaler_y.inverse_transform(np.expand_dims(y_val_pred, axis=1))\n",
    "\n",
    "mse_inv = mean_squared_error(y_val_inv, y_val_inv_pred)\n",
    "print(np.sqrt(mse_inv))\n",
    "\n",
    "df[\"revenue_m\"].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84fb10e4-613d-4c48-973b-ac390aa6aada",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming you have your predictions in `y_pred` and actual values in `y_true`\n",
    "m, b = np.polyfit(np.squeeze(y_val_inv), np.squeeze(y_val_inv_pred), 1)\n",
    "x = np.linspace(min(y_val_inv), max(y_val_inv), 30)\n",
    "\n",
    "plt.scatter(y_val_inv, y_val_inv_pred, s=6)\n",
    "plt.xlabel('True Values')\n",
    "plt.ylabel('Predictions (million $)')\n",
    "plt.title('True Values vs Predictions')\n",
    "plt.plot(x, m*x+b, color='red')  # Identity line\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "730e219c-fc75-48f1-a73f-8aa311c2c25a",
   "metadata": {},
   "source": [
    "### Neural Network\n",
    "\n",
    "Neural networks can also work really well for regression estimation tasks.\n",
    "\n",
    "We can use the Pytorch library to build our model! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5e52523-87c2-4ba5-8149-e143e7efb7ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to PyTorch tensors\n",
    "X_train_tensor = torch.tensor(X_train, dtype=torch.float32)\n",
    "y_train_tensor = torch.tensor(y_train, dtype=torch.float32).view(-1, 1)\n",
    "\n",
    "X_val_tensor = torch.tensor(X_val, dtype=torch.float32)\n",
    "y_val_tensor = torch.tensor(y_val, dtype=torch.float32).view(-1, 1)\n",
    "\n",
    "X_test_tensor = torch.tensor(X_test, dtype=torch.float32)\n",
    "y_test_tensor = torch.tensor(y_test, dtype=torch.float32).view(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aabb1c32-8224-4376-9e64-9441e75934f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: Define the DNN model\n",
    "class SimpleDNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SimpleDNN, self).__init__()\n",
    "        self.fc1 = nn.Linear(X_train_tensor.shape[1], 128)  # Input layer to hidden layer\n",
    "        self.fc2 = nn.Linear(128, 64) \n",
    "        self.fc3 = nn.Linear(64, 64)\n",
    "        self.fc4 = nn.Linear(64, 32)\n",
    "        self.fc5 = nn.Linear(32, 1)                         # Hidden layer to output\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.fc1(x))  # Activation for first layer\n",
    "        x = torch.relu(self.fc2(x))  # Activation for second layer\n",
    "        x = torch.relu(self.fc3(x))  # Activation for third layer\n",
    "        x = torch.relu(self.fc4(x))  # Activation for fourth layer\n",
    "        x = self.fc5(x)               # Output layer\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da01b11f-a2cb-472d-b5c5-9463d291f2e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SimpleDNN()\n",
    "criterion = nn.MSELoss()  # Mean Squared Error Loss\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.0001)\n",
    "\n",
    "num_epochs = 500\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    \n",
    "    optimizer.zero_grad()  # Clear the gradients\n",
    "    outputs = model(X_train_tensor)  # Forward pass\n",
    "    loss = criterion(outputs, y_train_tensor)  # Calculate loss\n",
    "    loss.backward()  # Backpropagation\n",
    "    optimizer.step()  # Update weights\n",
    "\n",
    "    # Print training progress\n",
    "    if (epoch + 1) % 100 == 0:\n",
    "        print(f'Epoch [{epoch + 1}/{num_epochs}], Loss: {loss.item():.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44ee10d7-5a36-476f-9490-aadccc483540",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the model on the validation set\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    val_outputs = model(X_val_tensor)\n",
    "    val_loss = criterion(val_outputs, y_val_tensor)\n",
    "\n",
    "print(f'Validation Loss (MSE): {val_loss.item():.4f}')\n",
    "\n",
    "# Optional: Evaluate on the test set\n",
    "with torch.no_grad():\n",
    "    test_outputs = model(X_test_tensor)\n",
    "    test_loss = criterion(test_outputs, y_test_tensor)\n",
    "\n",
    "print(f'Test Loss (MSE): {test_loss.item():.4f}')\n",
    "\n",
    "print(\"\\nPearson correlation coefficient, Validation: \", np.corrcoef(np.array(y_val_tensor)[:,0], np.array(val_outputs)[:,0])[0,1])\n",
    "val_r2 = r2_score(np.array(y_val_tensor)[:,0], np.array(val_outputs)[:,0])\n",
    "print(f'Validation R^2 Score: {val_r2:.4f}')\n",
    "\n",
    "\n",
    "print(\"\\nPearson correlation coefficient, Test: \", np.corrcoef(np.array(y_test_tensor)[:,0], np.array(test_outputs)[:,0])[0,1])\n",
    "test_r2 = r2_score(np.array(y_test_tensor)[:,0], np.array(test_outputs)[:,0])\n",
    "print(f'Test R^2 Score: {test_r2:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c673f6b3-9b12-4e98-91b6-b6b223c13e7b",
   "metadata": {},
   "source": [
    "#### Great!\n",
    "\n",
    "That's all for now - I really hope you enjoyed this tour of Pandas and that you found the exercises useful. \n",
    "\n",
    "There is still so much left unexplored. If you can dream it - you can probably do it with Pandas. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
